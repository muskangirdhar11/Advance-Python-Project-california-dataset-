# -*- coding: utf-8 -*-
"""project  w4 adv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOdhHToMzQYTYy9hP4AzaTzUIOuCEsQ5

##INTRODUCTION:
The given data set is about the california housing data.In this data there are 10 attributes which are lattitude,longitude,housing_median_age,total_rooms
,total_bedrooms,population,median_income,median_house_value,ocean_proximity

There are 10 numeric data and 1 nominal data. Let's differentiate them by
their data types:


**1. Continious data**: Continuous data are measurable; they are in the form of fractions or decimal.

Eg-longitude,lattitude,median_income,median_house_income

**2. Discrete Data** : Discrete data are countable and finite; they are whole numbers or integers
Eg- total_rooms,total_bedrooms,population,housing_median_age

**3. Categorical Data**: Categorical data is a form of qualitative data that can be grouped into categories instead of measured numerically.
Eg- ocean_proximity(Nominal data)

#**Use of different libraies**:

#Matplotlib:
This library is responsible for **plotting numerical data.** And that’s why it is used in data analysis. It is also an open-source library and plots high-defined figures like p**ie charts, histograms, scatterplots, graphs**, etc

#Pandas:
Pandas are an important library for data scientists. It is an open-source machine learning library that provides flexible high-level data structures and a variety of analysis tools. It eases data analysis, data manipulation, and cleaning of data. Pandas support operations like **Sorting, Re-indexing, Iteration, Concatenation, Conversion of data, Visualizations, Aggregations, etc**.

#Numpy:
The name “Numpy” stands for “Numerical Python”. It is the commonly used library. It is a popular machine learning library that supports large **matrices and multi-dimensional data**. It consists of **in-built mathematical functions** for easy computations. Even libraries like TensorFlow use Numpy internally to perform several operations on tensors. Array Interface is one of the key features of this library.
"""

# Importing necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy

#loading the data
cal_housing_data = pd.read_excel('/content/housing+(1).xlsx')

# checking total rows and columns
cal_housing_data.shape

"""##Q1 What is the average median income of the data set and check the distribution of data using appropriate plots. Please explain the distribution of the plot.

#Average Median Income
"""

print('Average Median Income --> ',round(cal_housing_data['median_income'].mean(),2))

"""Ans. it shows that

# Distribution of Median Income
"""

# plotting a histogram with matplotlib

plt.hist(cal_housing_data['median_income'])
plt.title(label="Median income distribution")
plt.xlabel("Income in tens of thousands of US Dollars")
plt.show()

"""Median_income is right skewed

## Q2. Draw an appropriate plot to see the distribution of housing_median_age and explain your observation
"""

plt.hist(cal_housing_data['housing_median_age'])
plt.title('Plot of Housing Median Age')
plt.xlabel('Median Age of Houses')
sns.set_style("white")
plt.grid(True)
plt.show()

"""From the above histogram, we have observed that it is distributed symmetrically with a outliar

## Q3. Show with the help of visualization, how median_income and median_house_values are related?
"""

plt.figure(figsize=(9,5))
plt.scatter(x = cal_housing_data['median_income'],y = cal_housing_data['median_house_value'], alpha =0.3)
plt.xlabel('Median Income')
plt.ylabel('Median House Value')
plt.show()

"""**from the above plot we see that when the median_house_value increase then the median_income alsi increases. therefore median_house_value is directly propotional to median_income.**

**Hence there is positive correlation between them.**
"""

# Calculating the correlation to observe the strength of the relationship
cal_housing_data['median_income'].corr(cal_housing_data['median_house_value'])

"""##Q4. Create a data set by deleting the corresponding examples from the data set for which total_bedrooms are not available."""

# calculating the total entries where total_bedrooms is null
# using isnull function to find the missing values
cal_housing_data['total_bedrooms'].isnull().sum()

# removing the entries where total_bedrooms is null
cal_housing_data_not_null = cal_housing_data.dropna(subset = ['total_bedrooms'])

#dropna() is use to drop rows and coloumns with null values

# deleted all rows for which value of total_bedrooms is null
cal_housing_data_not_null['total_bedrooms'].isnull().sum()

#showing the data
cal_housing_data_not_null.head()

print('number of rows before dropping null',cal_housing_data.shape[0])
print('number of rows after dropping null',cal_housing_data_not_null.shape[0])

"""## Q5. Create a data set by filling the missing data with the mean value of the total_bedrooms in the original data set"""

# calculating the total entries where total_bedrooms is null
cal_housing_data['total_bedrooms'].isnull().sum()

# copying the data set and making a new one
cal_housing_data_imputed = cal_housing_data.copy()

# get the mean value of total bedrooms for imputation
mean_to_impute = cal_housing_data['total_bedrooms'].mean()

# replacing nulls in the new dataset with the mean
cal_housing_data_imputed.loc[cal_housing_data_imputed['total_bedrooms'].isnull(),'total_bedrooms'] =  mean_to_impute

# showing the data
cal_housing_data.head()

# The number of null values for total_bedrooms column in the new dataset after imputation (should be zero)
cal_housing_data_imputed['total_bedrooms'].isnull().sum()

"""##Q6. Write a programming construct (create a user defined function) to calculate the median value of the data set wherever required"""

cal_housing_data[['total_bedrooms','housing_median_age']].mean()

#defining the get_median function,which will take columns from the dataset to calculate median

def get_median(data,*columns):  #format of taking the function:
  import pandas as pd
  if not columns:
    return data.median()
  else:
    return data[list(columns)].median()

#function working as expected
get_median(cal_housing_data,'longitude','total_bedrooms','housing_median_age')

"""##Q7. Plot latitude versus longitude and explain your observations.


"""

# plotting the latitude and longitude and adding colours for median house value
plt.figure(figsize=(10,7))
plt.scatter(cal_housing_data['longitude'],cal_housing_data['latitude'],alpha = 0.7)
plt.colorbar(label='median_house_value')
plt.show()

"""##Q8. Create a data set for which the ocean_proximity is ‘Near ocean’"""

# creating a new dataset where ocean_proximity is 'NEAR OCEAN'
cal_housing_data_near_ocean = cal_housing_data[cal_housing_data['ocean_proximity'] == 'NEAR OCEAN']

# checking the rows and columns in the new data set
cal_housing_data_near_ocean.shape

"""##Q9. Find the mean and median of the median income for the data set created in question 8.

> Indented block


"""

# Calculating and printing the Mean and median of the median income from the new dataset
print('Mean of median income: ',round(cal_housing_data_near_ocean['median_income'].mean(),2))
print('Median of median income: ',round(cal_housing_data_near_ocean['median_income'].median(),2))

"""**This means a person living in block group near the ocean makes 36,500 dollars per annum.**

##Q10. Please create a new column named total_bedroom_size. If the total bedrooms is 10 or less, it should be quoted as small. If the total bedrooms is 11 or more but less than 1000, it should be medium, otherwise it should be considered large.
"""

# using pandas cut method to split and label the data as per the requirements
# assigning it to a new dataset
cal_housing_data['total_bedroom_size'] = pd.cut(x = cal_housing_data['total_bedrooms'],bins = [0,11,1000,6446],labels = ['Small','Medium','Large'])

# storing the value count for each category
bedroom_sizes = cal_housing_data['total_bedroom_size'].value_counts()